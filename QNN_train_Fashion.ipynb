{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from QuICT_ml.ansatz_library import QNNLayer\n",
    "from QuICT_ml.utils.encoding import *\n",
    "from QuICT_ml.utils.ml_utils import *\n",
    "from QuICT_ml.model.QNN import QuantumNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "manual_seed(42)\n",
    "EPOCH = 50       # 训练总轮数\n",
    "BATCH_SIZE = 64 # 一次迭代使用的样本数\n",
    "LR = 0.001      # 梯度下降的学习率\n",
    "SEED = 42       # 随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples:  2048\n",
      "Testing examples:  1024\n"
     ]
    }
   ],
   "source": [
    "X_train = datasets.FashionMNIST(root=\"./data/\", train=True, download=True)\n",
    "batch_size = 64\n",
    "n_samples = 1024  # We will concentrate on the first 100 samples\n",
    "# 创建一个索引列表，包含所有类别（0-9）的样本\n",
    "idx = []\n",
    "for label in range(2):  # 遍历所有类别（0-9）\n",
    "    label_idx = np.where(X_train.targets == label)[0][:n_samples]  # 获取当前类别的样本索引\n",
    "    idx.append(label_idx)\n",
    "\n",
    "# 将所有类别的索引合并为一个数组\n",
    "idx = np.concatenate(idx)\n",
    "\n",
    "# 根据索引过滤数据\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "train_X = X_train.data\n",
    "train_Y = X_train.targets\n",
    "\n",
    "n_samples = 512\n",
    "X_test = datasets.FashionMNIST(root=\"./data/\", train=False, download=True)\n",
    "\n",
    "idx = []\n",
    "for label in range(2):  # 遍历所有类别（0-9）\n",
    "    label_idx = np.where(X_test.targets == label)[0][:n_samples]  # 获取当前类别的样本索引\n",
    "    idx.append(label_idx)\n",
    "\n",
    "# 将所有类别的索引合并为一个数组\n",
    "idx = np.concatenate(idx)\n",
    "\n",
    "# 根据索引过滤数据\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "test_X = X_test.data\n",
    "test_Y = X_test.targets\n",
    "print(\"Training examples: \", len(train_Y))\n",
    "print(\"Testing examples: \", len(test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ly\\.conda\\envs\\Qenv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def downscale(X, resize):\n",
    "    transform = transforms.Resize(size=resize)\n",
    "    X = transform(X) / 255.0\n",
    "    return X\n",
    "\n",
    "resized_train_X = downscale(train_X, (4, 4))\n",
    "resized_test_X = downscale(test_X, (4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining training examples:  2048\n",
      "Remaining testing examples:  1024\n"
     ]
    }
   ],
   "source": [
    "def remove_conflict(X, Y, resize):\n",
    "    x_dict = collections.defaultdict(set)\n",
    "    for x, y in zip(X, Y):\n",
    "        x_dict[tuple(x.numpy().flatten())].add(y.item())\n",
    "    X_rmcon = []\n",
    "    Y_rmcon = []\n",
    "    for x in x_dict.keys():\n",
    "        if len(x_dict[x]) == 1:\n",
    "            X_rmcon.append(np.array(x).reshape(resize))\n",
    "            Y_rmcon.append(list(x_dict[x])[0])\n",
    "    X = torch.from_numpy(np.array(X_rmcon))\n",
    "    Y = torch.from_numpy(np.array(Y_rmcon))\n",
    "    return X, Y\n",
    "\n",
    "nocon_train_X, nocon_train_Y = remove_conflict(resized_train_X, train_Y, (4, 4))\n",
    "nocon_test_X, nocon_test_Y = remove_conflict(resized_test_X, test_Y, (4, 4))\n",
    "print(\"Remaining training examples: \", len(nocon_train_Y))\n",
    "print(\"Remaining testing examples: \", len(nocon_test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_img(X, threshold):\n",
    "    X = X > threshold\n",
    "    X = X.type(torch.int)\n",
    "    return X\n",
    "\n",
    "threshold = 0.5\n",
    "bin_train_X = binary_img(nocon_train_X, threshold)\n",
    "bin_test_X = binary_img(nocon_test_X, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "train_X = bin_train_X.to(device)\n",
    "train_Y = nocon_train_Y.to(device)\n",
    "test_X = bin_test_X.to(device)\n",
    "test_Y = nocon_test_Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_encoding(X, device):\n",
    "    new_X = []\n",
    "    n_qubits = X[0].shape[0] * X[0].shape[1]\n",
    "    qe = Qubit(n_qubits, device)\n",
    "    for x in X:\n",
    "        qe.encoding(x)\n",
    "        new_X.append(qe.ansatz)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz_train_X = qubit_encoding(train_X, device)\n",
    "ansatz_test_X = qubit_encoding(test_X, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 848.056x645 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pqc = QNNLayer(list(range(4)), 4, device=device)\n",
    "params = nn.Parameter(torch.rand(1, 4, device=device), requires_grad=True)\n",
    "model_circuit = pqc.circuit_layer([\"XX\"], params)\n",
    "model_circuit.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qubits = list(range(16))\n",
    "readout_qubit = 16\n",
    "pqc = QNNLayer(data_qubits, readout_qubit, device=device)\n",
    "layers = [\"XX\", \"ZZ\"]\n",
    "params = nn.Parameter(torch.rand(2, 16, device=device), requires_grad=True)\n",
    "model_ansatz = pqc(layers, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(train_X, train_Y)\n",
    "test_dataset = data.TensorDataset(test_X, test_Y)\n",
    "train_loader = data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = QuantumNet(16, layers, encoding=\"qubit\", device=device)\n",
    "optim = torch.optim.Adam([dict(params=net.parameters(), lr=LR)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y_true, y_pred):\n",
    "    y_true = 2 * y_true.type(torch.float32) - 1.0\n",
    "    y_pred = 2 * y_pred - 1.0\n",
    "    loss = torch.clamp(1 - y_pred * y_true, min=0.0)\n",
    "    correct = torch.where(y_true * y_pred > 0)[0].shape[0]\n",
    "    return torch.mean(loss), correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1: 100%|██████████| 32/32 [12:51<00:00, 24.12s/it, accuracy=0.453, it=31, loss=1.010]\n",
      "Training epoch 2: 100%|██████████| 32/32 [12:56<00:00, 24.28s/it, accuracy=0.547, it=31, loss=0.954]\n",
      "Training epoch 3: 100%|██████████| 32/32 [12:52<00:00, 24.15s/it, accuracy=0.516, it=31, loss=1.025]\n",
      "Training epoch 4: 100%|██████████| 32/32 [12:51<00:00, 24.12s/it, accuracy=0.688, it=31, loss=0.912]\n",
      "Training epoch 5: 100%|██████████| 32/32 [12:51<00:00, 24.12s/it, accuracy=0.547, it=31, loss=0.944]\n",
      "Training epoch 6: 100%|██████████| 32/32 [12:51<00:00, 24.12s/it, accuracy=0.562, it=31, loss=0.965]\n",
      "Training epoch 7: 100%|██████████| 32/32 [12:52<00:00, 24.14s/it, accuracy=0.625, it=31, loss=0.927]\n",
      "Training epoch 8: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.688, it=31, loss=0.909]\n",
      "Training epoch 9: 100%|██████████| 32/32 [12:51<00:00, 24.12s/it, accuracy=0.641, it=31, loss=0.889]\n",
      "Training epoch 10: 100%|██████████| 32/32 [12:51<00:00, 24.10s/it, accuracy=0.625, it=31, loss=0.868]\n",
      "Training epoch 11: 100%|██████████| 32/32 [12:51<00:00, 24.12s/it, accuracy=0.688, it=31, loss=0.823]\n",
      "Training epoch 12: 100%|██████████| 32/32 [12:56<00:00, 24.27s/it, accuracy=0.625, it=31, loss=0.894]\n",
      "Training epoch 13: 100%|██████████| 32/32 [12:55<00:00, 24.23s/it, accuracy=0.594, it=31, loss=0.865]\n",
      "Training epoch 14: 100%|██████████| 32/32 [12:54<00:00, 24.19s/it, accuracy=0.625, it=31, loss=0.855]\n",
      "Training epoch 15: 100%|██████████| 32/32 [12:55<00:00, 24.24s/it, accuracy=0.625, it=31, loss=0.788]\n",
      "Training epoch 16: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.578, it=31, loss=0.880]\n",
      "Training epoch 17: 100%|██████████| 32/32 [12:56<00:00, 24.26s/it, accuracy=0.672, it=31, loss=0.734]\n",
      "Training epoch 18: 100%|██████████| 32/32 [12:55<00:00, 24.22s/it, accuracy=0.641, it=31, loss=0.822]\n",
      "Training epoch 19: 100%|██████████| 32/32 [12:58<00:00, 24.32s/it, accuracy=0.672, it=31, loss=0.728]\n",
      "Training epoch 20: 100%|██████████| 32/32 [12:55<00:00, 24.22s/it, accuracy=0.594, it=31, loss=0.792]\n",
      "Training epoch 21: 100%|██████████| 32/32 [12:53<00:00, 24.18s/it, accuracy=0.625, it=31, loss=0.793]\n",
      "Training epoch 22: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.672, it=31, loss=0.778]\n",
      "Training epoch 23: 100%|██████████| 32/32 [12:54<00:00, 24.19s/it, accuracy=0.703, it=31, loss=0.690]\n",
      "Training epoch 24: 100%|██████████| 32/32 [12:54<00:00, 24.19s/it, accuracy=0.625, it=31, loss=0.779]\n",
      "Training epoch 25: 100%|██████████| 32/32 [12:53<00:00, 24.18s/it, accuracy=0.609, it=31, loss=0.839]\n",
      "Training epoch 26: 100%|██████████| 32/32 [12:55<00:00, 24.23s/it, accuracy=0.703, it=31, loss=0.676]\n",
      "Training epoch 27: 100%|██████████| 32/32 [12:53<00:00, 24.18s/it, accuracy=0.625, it=31, loss=0.779]\n",
      "Training epoch 28: 100%|██████████| 32/32 [12:55<00:00, 24.25s/it, accuracy=0.672, it=31, loss=0.680]\n",
      "Training epoch 29: 100%|██████████| 32/32 [12:55<00:00, 24.22s/it, accuracy=0.719, it=31, loss=0.625]\n",
      "Training epoch 30: 100%|██████████| 32/32 [12:54<00:00, 24.20s/it, accuracy=0.719, it=31, loss=0.621]\n",
      "Training epoch 31: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.703, it=31, loss=0.654]\n",
      "Training epoch 32: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.750, it=31, loss=0.625]\n",
      "Training epoch 33: 100%|██████████| 32/32 [12:54<00:00, 24.19s/it, accuracy=0.703, it=31, loss=0.671]\n",
      "Training epoch 34: 100%|██████████| 32/32 [13:02<00:00, 24.46s/it, accuracy=0.562, it=31, loss=0.857]\n",
      "Training epoch 35: 100%|██████████| 32/32 [12:55<00:00, 24.24s/it, accuracy=0.734, it=31, loss=0.642]\n",
      "Training epoch 36: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.766, it=31, loss=0.510]\n",
      "Training epoch 37: 100%|██████████| 32/32 [12:55<00:00, 24.24s/it, accuracy=0.609, it=31, loss=0.798]\n",
      "Training epoch 38: 100%|██████████| 32/32 [12:55<00:00, 24.23s/it, accuracy=0.672, it=31, loss=0.733]\n",
      "Training epoch 39: 100%|██████████| 32/32 [12:55<00:00, 24.22s/it, accuracy=0.688, it=31, loss=0.715]\n",
      "Training epoch 40: 100%|██████████| 32/32 [12:54<00:00, 24.20s/it, accuracy=0.547, it=31, loss=0.835]\n",
      "Training epoch 41: 100%|██████████| 32/32 [12:54<00:00, 24.19s/it, accuracy=0.562, it=31, loss=0.822]\n",
      "Training epoch 42: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.703, it=31, loss=0.690]\n",
      "Training epoch 43: 100%|██████████| 32/32 [12:54<00:00, 24.21s/it, accuracy=0.594, it=31, loss=0.811]\n",
      "Training epoch 44: 100%|██████████| 32/32 [12:53<00:00, 24.17s/it, accuracy=0.750, it=31, loss=0.539]\n",
      "Training epoch 45: 100%|██████████| 32/32 [12:53<00:00, 24.18s/it, accuracy=0.703, it=31, loss=0.660]\n",
      "Training epoch 46: 100%|██████████| 32/32 [12:53<00:00, 24.16s/it, accuracy=0.672, it=31, loss=0.720]\n",
      "Training epoch 47: 100%|██████████| 32/32 [12:54<00:00, 24.20s/it, accuracy=0.781, it=31, loss=0.514]\n",
      "Training epoch 48: 100%|██████████| 32/32 [12:54<00:00, 24.20s/it, accuracy=0.562, it=31, loss=0.918]\n",
      "Training epoch 49: 100%|██████████| 32/32 [12:55<00:00, 24.22s/it, accuracy=0.656, it=31, loss=0.676]\n",
      "Training epoch 50: 100%|██████████| 32/32 [12:54<00:00, 24.20s/it, accuracy=0.625, it=31, loss=0.796]\n",
      "Validating epoch 50: 100%|██████████| 16/16 [06:30<00:00, 24.38s/it, accuracy=0.641, it=15, loss=0.728]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 0.7297791242599487, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train epoch\n",
    "for ep in range(EPOCH):\n",
    "    net.train()\n",
    "    loader = tqdm.tqdm(\n",
    "        train_loader, desc=\"Training epoch {}\".format(ep + 1), leave=True\n",
    "    )\n",
    "    # train iteration\n",
    "    for it, (x_train, y_train) in enumerate(loader):\n",
    "        optim.zero_grad()\n",
    "        y_pred = net(x_train)\n",
    "\n",
    "        loss, correct = loss_func(y_train, y_pred)\n",
    "        accuracy = correct / len(y_train)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loader.set_postfix(\n",
    "            it=it,\n",
    "            loss=\"{:.3f}\".format(loss),\n",
    "            accuracy=\"{:.3f}\".format(accuracy),\n",
    "        )\n",
    "\n",
    "# Validation\n",
    "net.eval()\n",
    "loader_val = tqdm.tqdm(\n",
    "    test_loader, desc=\"Validating epoch {}\".format(ep + 1), leave=True\n",
    ")\n",
    "loss_val_list = []\n",
    "total_correct = 0\n",
    "for it, (x_test, y_test) in enumerate(loader_val):\n",
    "    y_pred = net(x_test)\n",
    "    loss_val, correct = loss_func(y_test, y_pred)\n",
    "    loss_val_list.append(loss_val.cpu().detach().numpy())\n",
    "    total_correct += correct\n",
    "    accuracy_val = correct / len(y_test)\n",
    "    loader_val.set_postfix(\n",
    "        it=it,\n",
    "        loss=\"{:.3f}\".format(loss_val),\n",
    "        accuracy=\"{:.3f}\".format(accuracy_val),\n",
    "    )\n",
    "avg_loss = np.mean(loss_val_list)\n",
    "avg_acc = total_correct / (len(loader_val) * BATCH_SIZE)\n",
    "print(\"Validation Average Loss: {}, Accuracy: {}\".format(avg_loss, avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
